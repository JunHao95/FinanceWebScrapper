name: Daily Finance Report
on:
  # Schedule to run Monday-Friday at 3 PM UTC (adjust timezone as needed)
  schedule:
    - cron: '0 15 * * 1-5'  # 3 PM UTC, weekdays only
  
  # Allow manual triggering for testing
  workflow_dispatch:
    inputs:
      tickers:
        description: 'Comma-separated ticker symbols'
        required: false
        default: 'AAPL,MSFT,GOOG,AMZN,TSLA'
      email:
        description: 'Email address to send report'
        required: false
        default: 'teejunhao@gmail.com'

jobs:
  run-finance-scraper:
    runs-on: ubuntu-latest
    timeout-minutes: 30  # Prevent jobs from running too long
    
    steps:
      - name: ğŸ“ Checkout Repository
        uses: actions/checkout@v4
        
      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'  # Cache pip dependencies for faster builds
          
      - name: ğŸ“¦ Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential
          
      - name: ğŸ“š Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: ğŸ§ª Test Connection Pooling
        run: |
          echo "Testing connection pooling setup..."
          python test_connection_pooling.py
          
      - name: ğŸ” Run Finance Scraper
        env:
          # API Keys (set these in GitHub Secrets)
          ALPHA_VANTAGE_API_KEY: ${{ secrets.ALPHA_VANTAGE_API_KEY }}
          FINHUB_API_KEY: ${{ secrets.FINHUB_API_KEY }}
          
          # Email Configuration (set these in GitHub Secrets)
          FINANCE_SENDER_EMAIL: ${{ secrets.FINANCE_SENDER_EMAIL }}
          FINANCE_SENDER_PASSWORD: ${{ secrets.FINANCE_SENDER_PASSWORD }}
          FINANCE_SMTP_SERVER: ${{ secrets.FINANCE_SMTP_SERVER }}
          FINANCE_SMTP_PORT: ${{ secrets.FINANCE_SMTP_PORT }}
          FINANCE_USE_TLS: ${{ secrets.FINANCE_USE_TLS }}
          
          # Connection Pooling Configuration
          CONNECTION_POOL_SIZE: 20
          CONNECTION_POOL_MAXSIZE: 20
          ENABLE_CONNECTION_POOLING: true
          PERFORMANCE_MONITORING: true
          
        run: |
          # Get inputs or use defaults
          TICKERS="${{ github.event.inputs.tickers || 'AAPL,MSFT,GOOG,AMZN,TSLA,NVDA,META' }}"
          EMAIL="${{ github.event.inputs.email || secrets.DEFAULT_EMAIL || 'teejunhao@gmail.com' }}"
          
          echo "ğŸš€ Starting Finance Scraper..."
          echo "ğŸ“Š Tickers: $TICKERS"
          echo "ğŸ“§ Email: $EMAIL"
          
          # Run the scraper with optimized settings
          python main.py \
            --tickers "$TICKERS" \
            --sources yahoo finviz alphavantage technical enhanced_sentiment \
            --fast-mode \
            --parallel \
            --max-workers 8 \
            --format excel \
            --email "$EMAIL" \
            --summary \
            --logging true \
            --log-level info \
            --saveReports true
            
      - name: ğŸ“Š Upload Reports as Artifacts
        uses: actions/upload-artifact@v3
        if: always()  # Upload even if scraper fails
        with:
          name: finance-reports-${{ github.run_number }}
          path: |
            output/**/*.xlsx
            output/**/*.csv
            reports/**/*
            logs/**/*.log
          retention-days: 30
          
      - name: ğŸ“‹ Display Run Summary
        if: always()
        run: |
          echo "ğŸ¯ Finance Scraper Execution Complete!"
          echo "ğŸ“… Run Date: $(date)"
          echo "ğŸ”¢ Run Number: ${{ github.run_number }}"
          echo "ğŸ“ Artifacts available for download"
          
          # Show log summary if available
          if [ -f "logs/stock_scraper.log" ]; then
            echo "ğŸ“ Last 10 log entries:"
            tail -10 logs/stock_scraper.log
          fi
